{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En este Notebook realizaremos detección, censura y remoción de atípicos utilizando los métodos de RIQ, media-desviación estándar, cuantiles y LOF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.legend_handler import HandlerPathCollection\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../src/visualization/')\n",
    "import diagnostic_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargando datos Boston House\n",
    "boston_dataset = pd.read_csv('../../datasets/raw/boston.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un dataframe con variables independientes. Usaremos solo 3 variables para propósitos de demostración\n",
    "#boston = boston_dataset.filter(['RM', 'LSTAT', 'CRIM'], axis=1)\n",
    "boston = boston_dataset[['RM', 'LSTAT', 'CRIM']].copy()\n",
    "\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos con la función de diagnóstico los valores extremos en RM\n",
    "diagnostic_functions.diagnostic_plots2(boston, 'RM')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_boundaries_RIQ(df, variable, distance):\n",
    "\n",
    "    # Calculamos las froteras (distribución sesgada)\n",
    "    # La distancia es pasada como argunmento\n",
    "\n",
    "    IQR = df[variable].quantile(0.75) - df[variable].quantile(0.25)\n",
    "\n",
    "    lower_boundary = df[variable].quantile(0.25) - (IQR * distance)\n",
    "    upper_boundary = df[variable].quantile(0.75) + (IQR * distance)\n",
    "\n",
    "    return upper_boundary, lower_boundary\n",
    "\n",
    "\n",
    "\n",
    "def find_boundaries_zscore(df, variable, distance):\n",
    "    lower_boundary = df[variable].mean() - (df[variable].std() * distance)\n",
    "    upper_boundary = df[variable].mean() + (df[variable].std() * distance)\n",
    "    return upper_boundary, lower_boundary\n",
    "\n",
    "def find_boundaries_quantile(df, variable):\n",
    "    lower_boundary = df[variable].quantile(0.05)\n",
    "    upper_boundary = df[variable].quantile(0.95)\n",
    "    return upper_boundary, lower_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontremos los límites RM usando la regla RIQ\n",
    "RM_upper_limit, RM_lower_limit = find_boundaries_RIQ(boston, 'RM',1.5)\n",
    "RM_upper_limit, RM_lower_limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Censura de valores atípicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Censuremos los outliers por los limites máximo y mínimo\n",
    "\n",
    "boston['RM_censured']= np.where(boston['RM'] > RM_upper_limit, RM_upper_limit,\n",
    "                       np.where(boston['RM'] < RM_lower_limit, RM_lower_limit, boston['RM']))\n",
    "\n",
    "boston.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostic_functions.diagnostic_plots2(boston,'RM_censured')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remoción de valores atípicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marquemos los outliers en el cto. de datos\n",
    "\n",
    "outliers_RM = np.where(boston['RM'] > RM_upper_limit, True,\n",
    "                       np.where(boston['RM'] < RM_lower_limit, True, False))\n",
    "outliers_RM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removemos del conjunto de datos solo los outliers en RM\n",
    "\n",
    "boston_trimmed = boston.loc[~outliers_RM ]\n",
    "boston.shape, boston_trimmed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploremos los valores extremos en los datos removidos\n",
    "# para la variable RM vemos muchos menos outliers \n",
    "# que en los datos originales\n",
    "diagnostic_functions.diagnostic_plots2(boston_trimmed, 'RM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detección y remociuón de atípicos utilizando LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Generamos los datos sintéticos (inliers) de entrenamiento para propositos de demostración\n",
    "X_inliers = 0.3 * np.random.randn(100, 2)\n",
    "X_inliers = np.r_[X_inliers + 2, X_inliers - 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los inliers\n",
    "X_inliers.shape\n",
    "plt.scatter(X_inliers[:,0],X_inliers[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generemos algunos outliers (20)\n",
    "X_outliers = np.random.uniform(low=-4, high=4, size=(20, 2))\n",
    "X = np.r_[X_inliers, X_outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los outliers generados\n",
    "X_outliers.shape\n",
    "plt.scatter(X_outliers[:,0],X_outliers[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ambos, inliers y outliers\n",
    "X.shape\n",
    "plt.scatter(X[:,0],X[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un narray indicando si es la observación es atípica (-1) o no (1)\n",
    "n_outliers = len(X_outliers)\n",
    "ground_truth = np.ones(len(X), dtype=int)\n",
    "ground_truth[-n_outliers:] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos y entrenamos LOF (default) y obtenemos y_pred = 1:inlier -1:outlier\n",
    "clf = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "y_pred = clf.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuantificamos los errores\n",
    "n_errors = (y_pred != ground_truth).sum()\n",
    "print(n_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos los scores\n",
    "X_scores = clf.negative_outlier_factor_\n",
    "X_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_legend_marker_size(handle, orig):\n",
    "    \"Customize size of the legend marker\"\n",
    "    handle.update_from(orig)\n",
    "    handle.set_sizes([20])\n",
    "\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], color=\"k\", s=3.0, label=\"Data points\")\n",
    "# Graficamos circulos con radio proporcional a los outlier scores\n",
    "radius = (X_scores.max() - X_scores) / (X_scores.max() - X_scores.min())\n",
    "scatter = plt.scatter(\n",
    "    X[:, 0],\n",
    "    X[:, 1],\n",
    "    s=1000 * radius,\n",
    "    edgecolors=\"r\",\n",
    "    facecolors=\"none\",\n",
    "    label=\"Outlier scores\",\n",
    ")\n",
    "plt.axis(\"tight\")\n",
    "plt.xlim((-5, 5))\n",
    "plt.ylim((-5, 5))\n",
    "plt.xlabel(\"prediction errors: %d\" % (n_errors))\n",
    "plt.legend(\n",
    "    handler_map={scatter: HandlerPathCollection(update_func=update_legend_marker_size)}\n",
    ")\n",
    "plt.title(\"Local Outlier Factor (LOF)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detección de atípicos basada en algoritmos de clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se deja como ejercicio"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "190668de10e562b941b9fa78ebe98ef0bf1d742fd52dd3ccdc64dbf44346f9f3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
