{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En este Notebook aplicaremos las tecnicas de normalización min-max, estandarización y normalización con la media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Clases para estandarización \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# El escalador - para escalamiento min-max \n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargando los datos\n",
    "data = pd.read_csv('../../datasets/raw/boston.csv')\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observemos los pamámetros estadísticos principales de cada\n",
    "# variable para darnos una idea del rango de valores\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diferentes variables tienen diferentes rangos de valores representados por la media (mean), max, min y desviación estandar, etc. En otras palabras, tienen diferentes magnitudes o escalas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separemos los datos en los sets de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('MEDV', axis=1),\n",
    "                                                    data['MEDV'],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización Mix-Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos el escalador\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Entrenamos el escalador en el set de entrenamiento\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transforma los sets de entrenamiento y prueba \n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El escalador guarda los valores máximos de las variables\n",
    "# aprendidas del set de entrenamiento\n",
    "scaler.data_max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El escalador también guarda el rango de los \n",
    "# valores (max -  min)\n",
    "\n",
    "scaler.data_range_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformemos los arreglos NumPy resultantes \n",
    "# en dataframes para el resto del ejercicio\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos el set de entrenamiento original:\n",
    "np.round(X_train.describe().transpose(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos el set de entrenamiento normalizado: en particular los valores mínimos y máximos\n",
    "np.round(X_train_scaled.describe().transpose(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparemos la distribución de las variables antes y después del escalamiento\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 5))\n",
    "\n",
    "ax1.set_title('Antes del escalamiento')\n",
    "sns.kdeplot(X_train['RM'], ax=ax1)\n",
    "sns.kdeplot(X_train['LSTAT'], ax=ax1)\n",
    "sns.kdeplot(X_train['CRIM'], ax=ax1)\n",
    "\n",
    "ax2.set_title('Después del escalamiento Min-Max')\n",
    "sns.kdeplot(X_train_scaled['RM'], ax=ax2)\n",
    "sns.kdeplot(X_train_scaled['LSTAT'], ax=ax2)\n",
    "sns.kdeplot(X_train_scaled['CRIM'], ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que los valores están ahora limitados a un valor máximo de 1 pero las distribuciones no están centradas alrededor de zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estandarización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarización: con el StandardScaler de sklearn\n",
    "\n",
    "# Inicializa el escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Entrena el escalador en el set de entrenamiento\n",
    "# Aprende los parámetros \n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transforma los sets de entrenamiento y prueba \n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El escalador guarda la media de las variables\n",
    "# aprendidas del set de entrenamiento\n",
    "\n",
    "print(scaler.mean_)\n",
    "\n",
    "# El escalador guarda la desviación estándar\n",
    "# de las variables aprendidas del set de entrenamiento\n",
    "print(scaler.scale_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformemos los arreglos NumPy resultantes \n",
    "# en dataframes para el resto del demo\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos el set de entrenamiento original: media y desviación estándar \n",
    "# Aqui usamos np.round para reducir el número de decimalaes a 1 \n",
    "np.round(X_train.describe(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos el set de entrenamiento normalizado: en particular la media y desviación estándar \n",
    "# Aqui usamos np.round para reducir el número  de decimalaes a 1 \n",
    "\n",
    "np.round(X_train_scaled.describe(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparemos la distribución de las variables antes y despues del escalamiento.\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 5))\n",
    "\n",
    "# Antes de la normalización\n",
    "ax1.set_title('Antes del escalamiento')\n",
    "sns.kdeplot(X_train['AGE'], ax=ax1)\n",
    "sns.kdeplot(X_train['DIS'], ax=ax1)\n",
    "sns.kdeplot(X_train['NOX'], ax=ax1)\n",
    "\n",
    "\n",
    "# Después de la normalización\n",
    "ax2.set_title('Después del escalamiento estándar')\n",
    "sns.kdeplot(X_train_scaled['AGE'], ax=ax2)\n",
    "sns.kdeplot(X_train_scaled['DIS'], ax=ax2)\n",
    "sns.kdeplot(X_train_scaled['NOX'], ax=ax2)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se preserva la distribución original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train['AGE'], X_train['NOX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train_scaled['AGE'], X_train_scaled['NOX'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización con la media con pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero, estimamos la media del set de entrenamiento\n",
    "\n",
    "means = X_train.mean(axis=0)\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora estimamos los valores  min y max, y su rango \n",
    "# usando el set the entrenamiento\n",
    "\n",
    "ranges = X_train.max(axis=0)-X_train.min(axis=0)\n",
    "ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenemos todos los parámetros para la normalización:\n",
    "\n",
    "X_train_scaled = (X_train - means) / ranges\n",
    "X_test_scaled = (X_test - means) / ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos el set de entrenamiento original: en particular la media y valores min/max  \n",
    "\n",
    "np.round(X_train.describe().transpose(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos el set de entrenamiento normalizado: media y valores min/max  \n",
    "\n",
    "np.round(X_train_scaled.describe().transpose(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparemos la distribución de las variables antes y despues del escalamiento\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 5))\n",
    "\n",
    "# Antes del escalamiento\n",
    "ax1.set_title('Antes del escalamiento')\n",
    "sns.kdeplot(X_train['AGE'], ax=ax1)\n",
    "sns.kdeplot(X_train['DIS'], ax=ax1)\n",
    "sns.kdeplot(X_train['NOX'], ax=ax1)\n",
    "\n",
    "# Después del escalamiento\n",
    "ax2.set_title('Después de la normalización por la media')\n",
    "sns.kdeplot(X_train_scaled['AGE'], ax=ax2)\n",
    "sns.kdeplot(X_train_scaled['DIS'], ax=ax2)\n",
    "sns.kdeplot(X_train_scaled['NOX'], ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalización por la media con Scikit-learn se deja como ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalización con la norma $𝐿_{1}$ del vector se deja como ejercicio\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "190668de10e562b941b9fa78ebe98ef0bf1d742fd52dd3ccdc64dbf44346f9f3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
